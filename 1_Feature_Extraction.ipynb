{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Set and  Feature Extraction\n",
    "\n",
    "In this notebook, I will explain how to load and pre-process images using PyTorch `Dataset` and `DataLoader` classes. Then, I will extract encoded features for each image using CNNs. . \n",
    "\n",
    "Outline of this notebook:\n",
    "- [Step 1](#step1): Writing custom PyTorch Dataset\n",
    "- [Step 2](#step2): Using the Data Loader to obtain Batches\n",
    "- [Step 3](#step3): Extracting features of all dataset images using CNN Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## Step 1: Writing Custom PyTorch Dataset\n",
    "\n",
    "I wrote a custom PyTorch [Dataset](http://pytorch.org/docs/master/data.html#torch.utils.data.DataLoader) to recursively load all images in a directory with their paths. This dataset is an instance of my custom `ImagesDataset` class in **images_dataset.py**.  If you are unfamiliar with data loaders and datasets, you are encouraged to review [my post](http://www.sefidian.com/2022/03/09/writing-custom-datasets-and-dataloader-in-pytorch/) or [this PyTorch tutorial](http://pytorch.org/tutorials/beginner/data_loading_tutorial.html).\n",
    "\n",
    "#### Exploring the `__getitem__` Method\n",
    "\n",
    "The `__getitem__` method in the `ImagesDataset` class determines how an image-path pair is pre-processed before being incorporated into a batch.  This is true for all `Dataset` classes in PyTorch; if this is unfamiliar to you, please review [this link](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html). \n",
    "\n",
    "#### Image Pre-Processing \n",
    "\n",
    "Image pre-processing is relatively straightforward (from the `__getitem__` method in the `ImagesDataset` class):\n",
    "```python\n",
    "# Convert image to tensor and pre-process using transform\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "if self.transform is not None:\n",
    "    image = self.transform(image)\n",
    "```\n",
    "\n",
    "The `ImagesDataset` takes as input a number of arguments that can be explored in **data_loader.py**. Take the time to explore these arguments now by opening **images_dataset.py**. \n",
    "1. **`transform`** - an [image transform](http://pytorch.org/docs/master/torchvision/transforms.html) specifying how to pre-process the images and convert them to PyTorch tensors before using them as input to the CNN encoder.  I will define transforms in `transformer` variable.\n",
    "2. **`directory`** - determines the directory to search for image files.\n",
    "3. **`extensions`** - image file extensions to search for within the directory. \n",
    "\n",
    "After loading the image in the directory, the image is pre-processed using the transform that was supplied when instantiating the data loader.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from images_dataset import ImagesDataset\n",
    "from model import EncoderCNN\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import configs\n",
    "from configs import images_dir, batch_size, embedding_size, image_resize, extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to pre-process the training images.\n",
    "transformer = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((image_resize, image_resize)),\n",
    "        # convert the PIL Image to a tensor\n",
    "        transforms.ToTensor(),\n",
    "        # normalize image for pre-trained model\n",
    "        transforms.Normalize(\n",
    "            (0.485, 0.456, 0.406),\n",
    "            (0.229, 0.224, 0.225),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next code cell we define a `device` that we will use move PyTorch tensors to GPU (if CUDA is available).  Run this code cell before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cells below, I will initialize the dataset and data loader.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImagesDataset(\n",
    "    directory=images_dir, extensions=extensions, transform=transformer\n",
    ")\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "## Step 2: Using the Data Loader to obtain Batches\n",
    "\n",
    "The implementation of CNN encoder is in the **model.py** file. The `EncoderCNN` class takes `embedding_size` as an input argument. For this project, I incorporated a pre-trained CNN into the encoder. Specifically, I used the pre-trained ResNet-50 architecture (with the final fully-connected layer removed) to extract features from a batch of pre-processed images. The output is then flattened to a vector, before being passed through a `Linear` layer to transform the feature vector to have the same size as the word embedding.\n",
    "\n",
    "![Encoder](assets/encoder.png)\n",
    "\n",
    "You can amend the encoder in **model.py**, to experiment with other architectures. In particular, using a [different pre-trained model architecture](http://pytorch.org/docs/master/torchvision/models.html) could be good options. If you decide to modify the `EncoderCNN` class, save **model.py** and re-execute the code cell.\n",
    "\n",
    "Run the code cell below to instantiate the CNN encoder in `encoder`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderCNN(\n",
       "  (resnet): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (embed): Linear(in_features=2048, out_features=256, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing the encoder\n",
    "encoder = EncoderCNN(embedding_size=embedding_size)\n",
    "encoder.to(device)\n",
    "encoder.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "## Step 3: Extracting features of all dataset images using CNN Encoder\n",
    "\n",
    "In this step, I will pass the pre-processed images from the batch in **Step 2** of this notebook through the encoder, and then store `features` for each image in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e090b267d5e7495c8a213613e4638e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_features_df = pd.DataFrame([])\n",
    "for images_batch, paths in tqdm(data_loader):\n",
    "    images = images_batch.to(device)\n",
    "    encoder.zero_grad()\n",
    "\n",
    "    # Passing the inputs through the CNN model\n",
    "    with torch.no_grad():\n",
    "        features = encoder(images)\n",
    "    batch_df = pd.DataFrame(features.cpu().numpy(), index=paths)\n",
    "    full_features_df = full_features_df.append(batch_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>images/photo_2022-06-16_17-29-00.jpg</th>\n",
       "      <td>0.199145</td>\n",
       "      <td>0.246505</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.323195</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>0.092120</td>\n",
       "      <td>-0.434587</td>\n",
       "      <td>0.268099</td>\n",
       "      <td>-0.224246</td>\n",
       "      <td>-0.208385</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248163</td>\n",
       "      <td>0.146117</td>\n",
       "      <td>0.035693</td>\n",
       "      <td>-0.022854</td>\n",
       "      <td>-0.256254</td>\n",
       "      <td>0.216303</td>\n",
       "      <td>-0.334380</td>\n",
       "      <td>0.647641</td>\n",
       "      <td>-0.048660</td>\n",
       "      <td>0.621903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/photo_2022-06-16_17-29-01 (2) (3rd copy).jpg</th>\n",
       "      <td>-0.297781</td>\n",
       "      <td>0.430951</td>\n",
       "      <td>0.131061</td>\n",
       "      <td>0.092694</td>\n",
       "      <td>0.336686</td>\n",
       "      <td>-0.097079</td>\n",
       "      <td>-0.509302</td>\n",
       "      <td>-0.057603</td>\n",
       "      <td>-0.468720</td>\n",
       "      <td>-0.120154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184711</td>\n",
       "      <td>0.129619</td>\n",
       "      <td>-0.344921</td>\n",
       "      <td>0.355836</td>\n",
       "      <td>-0.158022</td>\n",
       "      <td>0.177382</td>\n",
       "      <td>-0.185563</td>\n",
       "      <td>0.337501</td>\n",
       "      <td>-0.328419</td>\n",
       "      <td>0.472292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/photo_2022-06-16_17-29-01 (2) (another copy).jpg</th>\n",
       "      <td>-0.297781</td>\n",
       "      <td>0.430951</td>\n",
       "      <td>0.131061</td>\n",
       "      <td>0.092694</td>\n",
       "      <td>0.336686</td>\n",
       "      <td>-0.097079</td>\n",
       "      <td>-0.509302</td>\n",
       "      <td>-0.057603</td>\n",
       "      <td>-0.468720</td>\n",
       "      <td>-0.120154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184711</td>\n",
       "      <td>0.129619</td>\n",
       "      <td>-0.344921</td>\n",
       "      <td>0.355836</td>\n",
       "      <td>-0.158022</td>\n",
       "      <td>0.177382</td>\n",
       "      <td>-0.185563</td>\n",
       "      <td>0.337501</td>\n",
       "      <td>-0.328419</td>\n",
       "      <td>0.472292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/photo_2022-06-16_17-29-01 (2) (copy).jpg</th>\n",
       "      <td>-0.297781</td>\n",
       "      <td>0.430951</td>\n",
       "      <td>0.131061</td>\n",
       "      <td>0.092694</td>\n",
       "      <td>0.336686</td>\n",
       "      <td>-0.097079</td>\n",
       "      <td>-0.509302</td>\n",
       "      <td>-0.057603</td>\n",
       "      <td>-0.468720</td>\n",
       "      <td>-0.120154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184711</td>\n",
       "      <td>0.129619</td>\n",
       "      <td>-0.344921</td>\n",
       "      <td>0.355836</td>\n",
       "      <td>-0.158022</td>\n",
       "      <td>0.177382</td>\n",
       "      <td>-0.185563</td>\n",
       "      <td>0.337501</td>\n",
       "      <td>-0.328419</td>\n",
       "      <td>0.472292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images/photo_2022-06-16_17-29-01 (2).jpg</th>\n",
       "      <td>-0.297781</td>\n",
       "      <td>0.430951</td>\n",
       "      <td>0.131061</td>\n",
       "      <td>0.092694</td>\n",
       "      <td>0.336686</td>\n",
       "      <td>-0.097079</td>\n",
       "      <td>-0.509302</td>\n",
       "      <td>-0.057603</td>\n",
       "      <td>-0.468720</td>\n",
       "      <td>-0.120154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184711</td>\n",
       "      <td>0.129619</td>\n",
       "      <td>-0.344921</td>\n",
       "      <td>0.355836</td>\n",
       "      <td>-0.158022</td>\n",
       "      <td>0.177382</td>\n",
       "      <td>-0.185563</td>\n",
       "      <td>0.337501</td>\n",
       "      <td>-0.328419</td>\n",
       "      <td>0.472292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         0         1    \\\n",
       "images/photo_2022-06-16_17-29-00.jpg                0.199145  0.246505   \n",
       "images/photo_2022-06-16_17-29-01 (2) (3rd copy)... -0.297781  0.430951   \n",
       "images/photo_2022-06-16_17-29-01 (2) (another c... -0.297781  0.430951   \n",
       "images/photo_2022-06-16_17-29-01 (2) (copy).jpg    -0.297781  0.430951   \n",
       "images/photo_2022-06-16_17-29-01 (2).jpg           -0.297781  0.430951   \n",
       "\n",
       "                                                         2         3    \\\n",
       "images/photo_2022-06-16_17-29-00.jpg                0.002800  0.323195   \n",
       "images/photo_2022-06-16_17-29-01 (2) (3rd copy)...  0.131061  0.092694   \n",
       "images/photo_2022-06-16_17-29-01 (2) (another c...  0.131061  0.092694   \n",
       "images/photo_2022-06-16_17-29-01 (2) (copy).jpg     0.131061  0.092694   \n",
       "images/photo_2022-06-16_17-29-01 (2).jpg            0.131061  0.092694   \n",
       "\n",
       "                                                         4         5    \\\n",
       "images/photo_2022-06-16_17-29-00.jpg                0.234513  0.092120   \n",
       "images/photo_2022-06-16_17-29-01 (2) (3rd copy)...  0.336686 -0.097079   \n",
       "images/photo_2022-06-16_17-29-01 (2) (another c...  0.336686 -0.097079   \n",
       "images/photo_2022-06-16_17-29-01 (2) (copy).jpg     0.336686 -0.097079   \n",
       "images/photo_2022-06-16_17-29-01 (2).jpg            0.336686 -0.097079   \n",
       "\n",
       "                                                         6         7    \\\n",
       "images/photo_2022-06-16_17-29-00.jpg               -0.434587  0.268099   \n",
       "images/photo_2022-06-16_17-29-01 (2) (3rd copy)... -0.509302 -0.057603   \n",
       "images/photo_2022-06-16_17-29-01 (2) (another c... -0.509302 -0.057603   \n",
       "images/photo_2022-06-16_17-29-01 (2) (copy).jpg    -0.509302 -0.057603   \n",
       "images/photo_2022-06-16_17-29-01 (2).jpg           -0.509302 -0.057603   \n",
       "\n",
       "                                                         8         9    ...  \\\n",
       "images/photo_2022-06-16_17-29-00.jpg               -0.224246 -0.208385  ...   \n",
       "images/photo_2022-06-16_17-29-01 (2) (3rd copy)... -0.468720 -0.120154  ...   \n",
       "images/photo_2022-06-16_17-29-01 (2) (another c... -0.468720 -0.120154  ...   \n",
       "images/photo_2022-06-16_17-29-01 (2) (copy).jpg    -0.468720 -0.120154  ...   \n",
       "images/photo_2022-06-16_17-29-01 (2).jpg           -0.468720 -0.120154  ...   \n",
       "\n",
       "                                                         246       247  \\\n",
       "images/photo_2022-06-16_17-29-00.jpg               -0.248163  0.146117   \n",
       "images/photo_2022-06-16_17-29-01 (2) (3rd copy)...  0.184711  0.129619   \n",
       "images/photo_2022-06-16_17-29-01 (2) (another c...  0.184711  0.129619   \n",
       "images/photo_2022-06-16_17-29-01 (2) (copy).jpg     0.184711  0.129619   \n",
       "images/photo_2022-06-16_17-29-01 (2).jpg            0.184711  0.129619   \n",
       "\n",
       "                                                         248       249  \\\n",
       "images/photo_2022-06-16_17-29-00.jpg                0.035693 -0.022854   \n",
       "images/photo_2022-06-16_17-29-01 (2) (3rd copy)... -0.344921  0.355836   \n",
       "images/photo_2022-06-16_17-29-01 (2) (another c... -0.344921  0.355836   \n",
       "images/photo_2022-06-16_17-29-01 (2) (copy).jpg    -0.344921  0.355836   \n",
       "images/photo_2022-06-16_17-29-01 (2).jpg           -0.344921  0.355836   \n",
       "\n",
       "                                                         250       251  \\\n",
       "images/photo_2022-06-16_17-29-00.jpg               -0.256254  0.216303   \n",
       "images/photo_2022-06-16_17-29-01 (2) (3rd copy)... -0.158022  0.177382   \n",
       "images/photo_2022-06-16_17-29-01 (2) (another c... -0.158022  0.177382   \n",
       "images/photo_2022-06-16_17-29-01 (2) (copy).jpg    -0.158022  0.177382   \n",
       "images/photo_2022-06-16_17-29-01 (2).jpg           -0.158022  0.177382   \n",
       "\n",
       "                                                         252       253  \\\n",
       "images/photo_2022-06-16_17-29-00.jpg               -0.334380  0.647641   \n",
       "images/photo_2022-06-16_17-29-01 (2) (3rd copy)... -0.185563  0.337501   \n",
       "images/photo_2022-06-16_17-29-01 (2) (another c... -0.185563  0.337501   \n",
       "images/photo_2022-06-16_17-29-01 (2) (copy).jpg    -0.185563  0.337501   \n",
       "images/photo_2022-06-16_17-29-01 (2).jpg           -0.185563  0.337501   \n",
       "\n",
       "                                                         254       255  \n",
       "images/photo_2022-06-16_17-29-00.jpg               -0.048660  0.621903  \n",
       "images/photo_2022-06-16_17-29-01 (2) (3rd copy)... -0.328419  0.472292  \n",
       "images/photo_2022-06-16_17-29-01 (2) (another c... -0.328419  0.472292  \n",
       "images/photo_2022-06-16_17-29-01 (2) (copy).jpg    -0.328419  0.472292  \n",
       "images/photo_2022-06-16_17-29-01 (2).jpg           -0.328419  0.472292  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 256)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_features_df.to_pickle(\"features.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next notebook, I will deduplicate images using these extracted features."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
